\diary{01/11/2017 Thích python vì nó quá đơn giản (và quá đẹp).}

Hướng dẫn online tại \href{http://magizbox.com/training/python/site/}{http://magizbox.com/training/python/site/}

\chapter{Nhập môn Python}

\subsection{Mục tiêu của khóa học}

\textbf{Ưu điểm của khóa học}

\begin{itemize}
  \item Dành cho người mới bắt đầu, chưa từng học lập trình hoặc cho những ai muốn ôn lại kiến thức căn bản về lập trình python.
  \item Dễ học, dễ thực hành, ví dụ trực quan thú vị, không yêu cầu cao về máy móc hay phần mềm đi kèm.
  \item Ví dụ mẫu nhiều, trực quan, thú vị.
\end{itemize}

Kết thúc khóa học bạn sẽ học được gì?

\begin{itemize}
  \item Xây dựng 5 dự án đơn giản với Python 3
\end{itemize}

Với những kiến thức bạn có thể làm gì?

\begin{itemize}
  \item Lập trình viên Python tại các công ty phần mềm
\end{itemize}

\subsection{Đối tượng học viên}

\begin{itemize}
  \item Những bạn chưa từng lập trình
  \item Những bạn đã có kinh nghiệm lập trình nhưng chưa lập trình python
\end{itemize}

\section{Giới thiệu}

\textbf{Python} is a general-purpose interpreted, interactive, object-oriented, and high-level programming language. It was created by Guido van Rossum during 1985- 1990. Like Perl, Python source code is also available under the GNU General Public License (GPL). This tutorial gives enough understanding on Python programming language.

\textbf{Python is Interpreted}: Python is processed at runtime by the interpreter. You do not need to compile your program before executing it. This is similar to PERL and PHP.

\textbf{Python is Interactive}: You can actually sit at a Python prompt and interact with the interpreter directly to write your programs.

\textbf{Python is Object-Oriented}: Python supports Object-Oriented style or technique of programming that encapsulates code within objects.

\textbf{Python is Beginner Friendly}: Python is a great language for the beginner-level programmers and supports the development of a wide range of applications from simple text processing to WWW browsers to games.

\textbf{Sách}

\href{https://docs.google.com/document/d/1gQFMXZtynpuTenoOQNGCHttArT4NspTWcyJQr5ps9Mk/edit?usp=sharing}{Tập hợp các sách python}

\textbf{Khoá học}

\href{1frO9QYhgsXbMzcyXoA4czWkxTWF8RBTJVf9uoO1rElU}{Tập hợp các khóa học python}

\textbf{Tham khảo}

\href{http://blog.tryolabs.com/2015/12/15/top-10-python-libraries-of-2015/}{Top 10 Python Libraries Of 2015}

\section{Cài đặt}

\subsection{Trên Windows}

\textbf{Anaconda 4.3.0}

Anaconda is BSD licensed which gives you permission to use Anaconda commercially and for redistribution.

1. Download the installer

2. Optional: Verify data integrity with MD5 or SHA-256
3. Double-click the .exe file to install Anaconda and follow the instructions on the screen

Python 3.6 version
64-BIT INSTALLER
Python 2.7 version
64-BIT INSTALLER
Step 2. Discover the Map

https://docs.python.org/2/library/index.html

\subsection{Trên CentOS}

Developer tools

The Development tools will allow you to build and compile software from source code. Tools for building RPMs are also included, as well as source code management tools like Git, SVN, and CVS.

\begin{lstlisting}[language=bash]
yum groupinstall "Development tools"
yum install zlib-devel
yum install bzip2-devel
yum install openssl-devel
yum install ncurses-devel
yum install sqlite-devel
\end{lstlisting}

Python & Anaconda
Anaconda is BSD licensed which gives you permission to use Anaconda commercially and for redistribution.

\begin{lstlisting}[language=bash]
cd /opt
wget --no-check-certificate https://www.python.org/ftp/python/2.7.6/Python-2.7.6.tar.xz
tar xf Python-2.7.6.tar.xz
cd Python-2.7.6
./configure --prefix=/usr/local
make && make altinstall
## link
ln -s /usr/local/bin/python2.7 /usr/local/bin/python
# final check
which python
python -V
# install Anaconda
cd ~/Downloads
wget https://repo.continuum.io/archive/Anaconda-2.3.0-Linux-x86_64.sh
bash ~/Downloads/Anaconda-2.3.0-Linux-x86_64.sh
\end{lstlisting}

\section{Biến - Hộp nhỏ}

\section{123s - Số trong Python}

\subsection{Print, print}

\begin{lstlisting}[language=python]
print "Hello World"
\end{lstlisting}

\subsection{Conditional}

\begin{lstlisting}[language=Python]
if you_smart:
    print "learn python"
else:
    print "go away"
\end{lstlisting}

\subsection{Loop}

In general, statements are executed sequentially: The first statement in a function is executed first, followed by the second, and so on. There may be a situation when you need to execute a block of code several number of times.

Programming languages provide various control structures that allow for more complicated execution paths. A loop statement allows us to execute a statement or group of statements multiple times. The following diagram illustrates a loop statement


Python programming language provides following types of loops to handle looping requirements.

while loop	Repeats a statement or group of statements while a given condition is TRUE. It tests the condition before executing the loop body.
for loop	Executes a sequence of statements multiple times and abbreviates the code that manages the loop variable.
nested loops	You can use one or more loop inside any another while, for or do..while loop.

\subsection{While Loop}

A while loop statement in Python programming language repeatedly executes a target statement as long as a given condition is true.

Syntax

The syntax of a while loop in Python programming language is

\begin{lstlisting}[language=Python]
while expression:
   statement(s)
\end{lstlisting}

Example

\begin{lstlisting}[language=Python]
count = 0
while count < 9:
   print 'The count is:', count
   count += 1
print "Good bye!"
\end{lstlisting}


\subsection{For Loop}

It has the ability to iterate over the items of any sequence, such as a list or a string.

Syntax

\begin{lstlisting}[language=Python]
for iterating_var in sequence:
   statements(s)
\end{lstlisting}

If a sequence contains an expression list, it is evaluated first. Then, the first item in the sequence is assigned to the iterating variable iterating_var. Next, the statements block is executed. Each item in the list is assigned to iterating_var, and the statement(s) block is executed until the entire sequence is exhausted.

Example

\begin{lstlisting}[language=Python]
for i in range(10):
    print "hello", i

for letter in 'Python':
   print 'Current letter :', letter

fruits = ['banana', 'apple',  'mango']
for fruit in fruits:
   print 'Current fruit :', fruit

print "Good bye!"
\end{lstlisting}

Yield and Generator

Yield is a keyword that is used like return, except the function will return a generator.

\begin{lstlisting}[language=Python]
def createGenerator():
    yield 1
    yield 2
    yield 3
mygenerator = createGenerator() # create a generator
print(mygenerator) # mygenerator is an object!
# <generator object createGenerator at 0xb7555c34>
for i in mygenerator:
    print(i)
# 1
# 2
# 3
\end{lstlisting}


Visit Yield and Generator explained for more information

Functions

Variable-length arguments

\begin{lstlisting}[language=Python]
def functionname([formal_args,] *var_args_tuple ):
   "function_docstring"
   function_suite
   return [expression]
\end{lstlisting}

Example

\begin{lstlisting}[language=Python]
#!/usr/bin/python

# Function definition is here
def printinfo( arg1, *vartuple ):
   "This prints a variable passed arguments"
   print "Output is: "
   print arg1
   for var in vartuple:
      print var
   return;

# Now you can call printinfo function
printinfo( 10 )
printinfo( 70, 60, 50 )
\end{lstlisting}

Coding Convention
Code layout
Indentation: 4 spaces

Suggest Readings

"Python Functions". www.tutorialspoint.com
"Python Loops". www.tutorialspoint.com
"What does the “yield” keyword do?". stackoverflow.com
"Improve Your Python: 'yield' and Generators Explained". jeffknupp.com

\textbf{Vấn đề với mảng}

\begin{item}
  \item Random Sampling \footnote{tham khảo [pytorch](http://pytorch.org/docs/master/torch.html?highlight=randn#torch.randn), [numpy](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html))} - sinh ra một mảng ngẫu nhiên trong khoảng (0, 1), mảng ngẫu nhiên số nguyên trong khoảng (x, y), mảng ngẫu nhiên là permutation của số từ 1 đến n
\end{item}

\section{Cấu trúc dữ liệu}

\subsection{Number}

Basic Operation

\begin{lstlisting}[language=Python]
1
1.2
1 + 2
abs(-5)
\end{lstlisting}

\subsection{Collection}

In this post I will cover 4 most popular data types in python list, tuple, set, dictionary

List
The most basic data structure in Python is the sequence. Each element of a sequence is assigned a number - its position or index. The first index is zero, the second index is one, and so forth.

The list is a most versatile datatype available in Python which can be written as a list of comma-separated values (items) between square brackets. Important thing about a list is that items in a list need not be of the same type.

Usage

A list keeps order, dict and set don't: when you care about order, therefore, you must use list (if your choice of containers is limited to these three, of course)
Most Popular Operations

Create a list
a = ["a", "b", 3]
Access values in list
a[1]
Updated List
a[0] = 5
Delete list elements
del a[1]
Reverse a list
a[::-1]
Itertools
[a + b for (a, b) in itertools.product(x, y)]
Select random elements in list
random.choice(x)
random.sample(x, 3)
Create a list
a = [1, 2, 3]
# [1, 2, 3]
Access values in list
list1 = ['physics', 'chemistry', 1997, 2000]
list2 = [1, 2, 3, 4, 5, 6, 7 ]

print list1[0]   # physics

print list2[1:5] # [2, 3, 4, 5]
Updated lists
list = ['physics', 'chemistry', 1997, 2000]
print list[2] # 1997

list[2] = 2001
print list[2] # 2001
Delete list elements
list1 = ['physics', 'chemistry', 1997, 2000];

print list1
# ['physics', 'chemistry', 1997, 2000]

del list1[2]

print list1
# ['physics', 'chemistry', 2000]
Reverse a list
[1, 3, 2][::-1]
# [2, 3, 1]
Itertools
import itertools

x = [1, 2, 3]
y = [2, 4, 5]

[a + b for (a, b) in itertools.product(x, y)]
# [3, 5, 6, 4, 6, 7, 5, 7, 8]
Select random elements in list
import random

x = [13, 23, 14, 52, 6, 23]

random.choice(x) # 52

random.sample(x, 3) # [23, 14, 52]
Tuples
A tuple is a sequence of immutable Python objects. Tuples are sequences, just like lists. The differences between tuples and lists are, the tuples cannot be changed unlike lists and tuples use parentheses, whereas lists use square brackets.

Usage

Tuples have structure, lists have order
Tuples being immutable there is also a semantic distinction that should guide their usage. Tuples are heterogeneous data structures (i.e., their entries have different meanings), while lists are homogeneous sequences
Most Popular Operations

Create a tuple
t = ("a", 1, 2)
Accessing Values in Tuples
t[0], t[1:]
Updating Tuples
Not allowed
Create a tuple
tup1 = ('physics', 'chemistry', 1997, 2000);
tup2 = (1, 2, 3, 4, 5 );
tup3 = "a", "b", "c", "d";
tup4 = ()
tup5 = (50, )
Accessing Values in Tuples
#!/usr/bin/python

tup1 = ('physics', 'chemistry', 1997, 2000);
tup2 = (1, 2, 3, 4, 5, 6, 7 );

tup1[0]
# physics

tup2[1:5]
[2, 3, 4, 5]
Updating Tuples
Tuples are immutable which means you cannot update or change the values of tuple elements. You are able to take portions of existing tuples to create new tuples as the following example demonstrates

tup1 = (12, 34.56);
tup2 = ('abc', 'xyz');

# Following action is not valid for tuples
# tup1[0] = 100;

# So let's create a new tuple as follows
tup3 = tup1 + tup2;
print tup3
Set
Sets are lists with no duplicate entries.

The sets module provides classes for constructing and manipulating unordered collections of unique elements. Common uses include membership testing, removing duplicates from a sequence, and computing standard math operations on sets such as intersection, union, difference, and symmetric difference.

Usage

set forbids duplicates, list does not: also a crucial distinction.
Most Popular Operations

Create a set
x = set(["Postcard", "Radio", "Telegram"])
Add elements to a set
x.add("Mobile")
Remove elements to a set
x.remove("Radio")
Subset
y.issubset(x)
Intersection
x.intersection(y)
Difference between two sets
x.difference(y)
Create a set
x = set(["Postcard", "Radio", "Telegram"])
x
# set(['Postcard', 'Telegram', 'Radio'])
Add elements to a set
x = set(["Postcard", "Radio", "Telegram"])
x.add("Mobile")
x
# set(['Postcard', 'Telegram', 'Mobile', 'Radio'])
Remove elements to a set
x = set(["Postcard", "Radio", "Telegram"])
x.remove("Radio")
x
# set(['Postcard', 'Telegram'])
Subset
x = set(["a","b","c","d"])
y = set(["c","d"])
y.issubset(x)
# True
Intersection
x = set(["a","b","c","d"])
y = set(["c","d"])
x.intersection(y)
# set(['c', 'd'])
Difference between two sets
x = set(["Postcard", "Radio", "Telegram"])
y = set(["Radio","Television"])
x.difference(y)
# set(['Postcard', 'Telegram'])
Dictionary
Each key is separated from its value by a colon (:), the items are separated by commas, and the whole thing is enclosed in curly braces. An empty dictionary without any items is written with just two curly braces, like this: {}.

Keys are unique within a dictionary while values may not be. The values of a dictionary can be of any type, but the keys must be of an immutable data type such as strings, numbers, or tuples.

Usage

dict associates with each key a value, while list and set just contain values: very different use cases, obviously.
Most Popular Operations

Create a dictionary
d = {"a": 1, "b": 2, "c": 3}
Update dictionary
d["a"] = 4
Delete dictionary elements
del d["a"]
Create a dictionary
dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'}

print "dict['Name']: ", dict['Name']
print "dict['Age']: ", dict['Age']
Update dictionary
dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'}

dict['Age'] = 8; # update existing entry
dict['School'] = "DPS School"; # Add new entry


print "dict['Age']: ", dict['Age']
print "dict['School']: ", dict['School']
Delete dictionary elements
dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'}

del dict['Name']; # remove entry with key 'Name'
dict.clear();     # remove all entries in dict
del dict ;        # delete entire dictionary

print "dict['Age']: ", dict['Age']
print "dict['School']: ", dict['School']
Related Readings
Python Lists, tutorialspoint.com
Python Dictionary, tutorialspoint.com
Python Dictionary Methods, guru99
In Python, when to use a Dictionary, List or Set?, stackoverflow
What's the difference between lists and tuples?, stackoverflow

\subsection{String}

Format
'{0}, {1}, {2}'.format('a', 'b', 'c')
# 'a, b, c'
Regular Expressions
The aim of this chapter of our Python tutorial is to present a detailed led and descriptive introduction into regular expressions. This introduction will explain the theoretical aspects of regular expressions and will show you how to use them in Python scripts.

Regular Expressions are used in programming languages to filter texts or textstrings. It's possible to check, if a text or a string matches a regular expression.

There is an aspect of regular expressions which shouldn't go unmentioned: The syntax of regular expressions is the same for all programming and script languages, e.g. Python, Perl, Java, SED, AWK and even X#.

Functions
match function
This function attempts to match RE pattern to string with optional flags.

re.match(pattern, string, flags=0)
Example

import re

line = "Cats are smarter than dogs"

matched_object = re.match(r'(.*) are (.*?) .*', line, re.M | re.I)

if matched_object:
    print "matched_object.group()  : ", matched_object.group()
    print "matched_object.group(1) : ", matched_object.group(1)
    print "matched_object.group(2) : ", matched_object.group(2)
else:
    print "No match!!"
When the code is executed, it produces following results

matched_object.group()  :  Cats are smarter than dogs
matched_object.group(1) :  Cats
matched_object.group(2) :  smarter
search function
This function searches for first occurrence of RE pattern within stirng with optional flags

re.search(pattern, string, flags=0)
Example

#!/usr/bin/python
import re

line = "Cats are smarter than dogs"

search_object = re.search(r'dogs', line, re.M | re.I)
if search_object:
    print "search --> search_object.group() : ", search_object.group()
else:
    print "Nothing found!!"
When the code is executed, it produces following results

search --> search_object.group() :  dogs
sub function
This method replaces all occurrences of the RE pattern in string with repl, substituting all occurrences unless max provided. This method returns modified string.

re.sub(pattern, repl, string, max=0)
Example

#!/usr/bin/python
import re

phone = "2004-959-559 # This is Phone Number"

# Delete Python-style comments
num = re.sub(r'#.*$', "", phone)
print "Phone Num : ", num

# Remove anything other than digits
num = re.sub(r'\D', "", phone)
print "Phone Num : ", num
When the code is executed, it produces following results

Phone Num :  2004-959-559
Phone Num :  2004959559
Tokens Cheatsheet
Character Classes
.	any character except newline
/go.gle/
google goggle gogle
\w \d \s	word, digit, whitespace
/\w/
AaYyz09 ?!
/\d/
012345 aZ?
/\s/
0123456789 abcd?/
\W \D \S	not word, digit, whitespace
/\W/
abcded   1234 ?>
/\D/
abc 12345 ?<.
/\S/
abc   123?  <.
[abc]	any of a, b or c
/analy[sz]e/
analyse analyze analyxe
[^abc]	not a, b or c
/analy[^sz]e/
analyse analyze analyxe
[a-g]	character between a & g
/[2-4]/
demo1 demo2 demo3 demo4 demo5
Quantifiers & Alternation
a* a+ a?	0 or more, 1 or more, 0 or 1
/go*gle/
gogle gogle google gooooogle hgle
/go+gle/
ggle gogle google gooooogle hgle
/go?gle/
ggle gogle google gooooogle hgle
a{5}, a{2,}	exactly five, two or more
/go{5}gle/
gogle gogle google gooooogle hgle
/go{2,}gle/
gogle gogle google gooooogle hgle
a{1,3}	between one & three
/go{1,3}gle/
gogle gogle google gooogle gooooogle hgle
a+? a{2,}?	match as few as possible
/a+?/
a aa aaaaaa
/a{2,}?/
a aa aaaaaa
ab|cd	match ab or cd
/demo|example/
demo example example1
Anchors
^abc$	start / end of the string
/^abc$/
abc
/^abc/
abc abc
/abc$/
abc abc
\b \B	word, not-word boundary
/\bis\b/
This island is beautiful.
/\Bcat\B/
cat certificate
Escaped characters
\. \* \\	escaped special characters
/\./
username@exampe.com 300.000 USD
/\*/
abc@&%$*123
/\\/
abc@&%$\\123
\t \n \r	tab, linefeed, carriage return
/\t/
abc	def
/ab\n/
ab
/\r/
abc@&%$\\123
\u00A9	unicode escaped ©
/\u00A9/
Copyright©2017 - All rights reserved
Groups and Lockaround
(abc)	capture group
/(demo|example)[0-9]/
demo1example4demo
\1	backreference to group #1
/(abc|def)=\1/
abc=abc def=defabc=def
(?:abc)	non-capturing group
/(?:abc){3}/
abcabcabc abcabc
(?=abc)	positive lookahead
/t(?=s)/
tttssstttss
(?!abc)	negative lookahead
/t(?!s)/
tttssstttss
(?<=abc)	positive lookbehind
/(?<=foo)bar/
foobar fuubar
(?<!abc)	negative lookbehind
/(?<!foo)bar/
foobar fuubar
Related Readings

Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript, regex101.com
RegExr: Learn, Build, & Test RegEx, regexr.com

\subsection{Datetime}

Print current time

from datetime import datetime
datetime.now().strftime('%Y-%m-%d %H:%M:%S')
# '2015-12-29 14:02:27'
Get current time

import datetime
datetime.datetime.now()
# datetime(2009, 1, 6, 15, 8, 24, 78915)
Unixtime

import time
int(time.time())
Measure time elapsed

import time

start = time.time()
print("hello")
end = time.time()
print(end - start)
Moment
Dealing with dates in Python shouldn't have to suck.

Installation

pip install moment
Usage

import moment
from datetime import datetime

# Create a moment from a string
moment.date("12-18-2012")

# Create a moment with a specified strftime format
moment.date("12-18-2012", "%m-%d-%Y")

# Moment uses the awesome dateparser library behind the scenes
moment.date("2012-12-18")

# Create a moment with words in it
moment.date("December 18, 2012")

# Create a moment that would normally be pretty hard to do
moment.date("2 weeks ago")

# Create a future moment that would otherwise be really difficult
moment.date("2 weeks from now")

# Create a moment from the current datetime
moment.now()

# The moment can also be UTC-based
moment.utcnow()

# Create a moment with the UTC time zone
moment.utc("2012-12-18")

# Create a moment from a Unix timestamp
moment.unix(1355875153626)

# Create a moment from a Unix UTC timestamp
moment.unix(1355875153626, utc=True)

# Return a datetime instance
moment.date(2012, 12, 18).date

# We can do the same thing with the UTC method
moment.utc(2012, 12, 18).date

# Create and format a moment using Moment.js semantics
moment.now().format("YYYY-M-D")

# Create and format a moment with strftime semantics
moment.date(2012, 12, 18).strftime("%Y-%m-%d")

# Update your moment's time zone
moment.date(datetime(2012, 12, 18)).locale("US/Central").date

# Alter the moment's UTC time zone to a different time zone
moment.utcnow().timezone("US/Eastern").date

# Set and update your moment's time zone. For instance, I'm on the
# west coast, but want NYC's current time.
moment.now().locale("US/Pacific").timezone("US/Eastern")

# In order to manipulate time zones, a locale must always be set or
# you must be using UTC.
moment.utcnow().timezone("US/Eastern").date

# You can also clone a moment, so the original stays unaltered
now = moment.utcnow().timezone("US/Pacific")
future = now.clone().add(weeks=2)
Related Readings
How to get current time in Python, stackoverflow
Does Python's time.time() return the local or UTC timestamp?, stackoverflow
Measure time elapsed in Python?, stackoverflow
momnet, https://github.com/zachwill/moment

\subsection{Object}

Convert dict to object
Elegant way to convert a normal Python dict with some nested dicts to an object

class Struct:
    def __init__(self, **entries):
        self.__dict__.update(entries)
Then, you can use

> args = {'a': 1, 'b': 2}
> s = Struct(**args)
> s
< __main__.Struct instance at 0x01D6A738 >
> s.a
1
> s.b
2
Related Readings

stackoverflow, Convert Python dict to object?

\section{Lập trình hướng đối tượng}

Object Oriented Programming
Python has been an object-oriented language since it existed. Because of this, creating and using classes and objects are downright easy. This chapter helps you become an expert in using Python's object-oriented programming support.

If you do not have any previous experience with object-oriented (OO) programming, you may want to consult an introductory course on it or at least a tutorial of some sort so that you have a grasp of the basic concepts.

\subsection{Classes and Objects}

Classes can be thought of as blueprints for creating objects. When I define a BankAccount class using the class keyword, I haven't actually created a bank account. Instead, what I've created is a sort of instruction manual for constructing "bank account" objects. Let's look at the following example code:

\begin{lstlisting}[language=Python]
class BankAccount:
    id = None
    balance = 0

    def __init__(self, id, balance=0):
        self.id = id
        self.balance = balance

    def __get_balance(self):
        return self.balance

    def withdraw(self, amount):
        self.balance = self.balance - amount

    def deposit(self, amount):
        self.balance = self.balance + amount

john = BankAccount(1, 1000.0)
john.withdraw(100.0)
\end{lstlisting}

The class BankAccount line does not create a new bank account. That is, just because we've defined a BankAcount doesn't mean we've created on; we've merely outlined the blueprint to create a BankAccount object. To do so, we call the class's __init__ method with the proper number of arguments (minus self, which we'll get to in a moment)

So, to use the "blueprint" that we crated by defining the class BankAccount (which is used to create BankAccount objects), we call the class name almost as if it were a function: john = BankAccount(1, 1000.0). This line simple say "use the BankAccount blueprint to create me a new object, which I'll refer to as john".

The john object, known as an instance, is the realized version of the BankAccount class. Before we called BankAccount(), no BankAccount object existed. We can, of course, create as many BankAccount objects as we'd like. There is still, however, only one BankAccount class, regardless of how many instances of the class we create.

\subsection{self}

So what's with that self parameter to all of the BankAccount methods? What is it? Why, it's the instance, of course! Put another way, a method like withdraw defines the instructions for withdrawing money from some abstract customer's account. Calling john.withdraw(100) puts those instructions to use on the john instance.

So when we say def withdraw(self, amount):, we're saying, "here's how you withdraw money from a BankAccount object (which we'll call self) and a dollar figure (which we'll call amount). self is the instance of the BankAccount that  withdraw is being called on. That's not me making analogies, either. john.withdraw(100.0) is just shorthand for BankAccount.withdraw(john, 100.0), which is perfectly valid (if not often seen) code.

Constructors: __init__

self may make sense for other methods, but what about __init__? When we call __init__, we're in the process of creating an object, so how can there already be a self? Python allows us to extend the self pattern to when objects are constructed as well, even though it doesn't exactly fit. Just imagine that john = (1, 1000.0) is the same as calling john = BankAccount(john, 1, 1000.0); the john that's passed in is also made the result.

This is why when we call __init__, we initialize objects by saying things like self.id = id. Remember, since self is the instance, this is equivalent to saying john.id = id, which is the same as john.id= 1. Similarly, self.balance = balance is the same as john.balance = 1000.0. After these two lines, we consider the BankAccount object "initialized" and ready for use.

Be careful what you __init__

After __init__ has finished, the caller can rightly assume that the object is ready to use. That is, after john = BankAccount(1, 1000.0), we can start making deposit and withdraw calls on john; john is a fully-initialized object.

Inheritance
While Object-oriented Programming is useful as a modeling tool, it truly gains power when the concept of inheritance is introduced. Inheritance is the process by which a "child" class derives the data and behavior of a "parent" class. An example will definitely help us here.

Imagine we run a car dealership. We sell all types of vehicles, from motorcycles to trucks. We set ourselves apart from the competition by our prices. Specifically, how we determine the price of a vehicle on our lot: \$5,000 x number of wheels a vehicle has. We love buying back our vehicles as well. We offer a flat rate - 10\% of the miles driven on the vehicle. For trucks, that rate is \$10,000. For cars, \$8,000. For motorcycles, \$4,000.

If we wanted to create a sales system for our dealership using Object-oriented techniques, how would we do so? What would the objects be? We might have a Sale class, a Customer class, an Inventory class, and so forth, but we'd almost certainly have a Car, Truck, and Motorcycle class.

What would these classes look like? Using what we've learned, here's a possible implementation of the Car class:

\begin{lstlisting}[language=Python]
class Car(object):
    def __init__(self, wheels, miles, make, model, year, sold_on):
        self.wheels = wheels
        self.miles = miles
        self.make = make
        self.model = model
        self.year = year
        self.sold_on = sold_on

    def sale_price(self):
        if self.sold_on is not None:
            return 0.0  # Already sold
        return 5000.0 * self.wheels

    def purchase_price(self):
        if self.sold_on is None:
            return 0.0  # Not yet sold
        return 8000 - (.10 * self.miles)
\end{lstlisting}

OK, that looks pretty reasonable. Of course, we would likely have a number of other methods on the class, but I've shown two of particular interest to us: sale_price and purchase_price. We'll see why these are important in a bit.

Now that we've got the Car class, perhaps we should create a Truck class? Let's follow the same pattern we did for car:

\begin{lstlisting}[language=Python]
class Truck(object):
    def __init__(self, wheels, miles, make, model, year, sold_on):
        self.wheels = wheels
        self.miles = miles
        self.make = make
        self.model = model
        self.year = year
        self.sold_on = sold_on

    def sale_price(self):
        if self.sold_on is not None:
            return 0.0  # Already sold
        return 5000.0 * self.wheels

    def purchase_price(self):
        if self.sold_on is None:
            return 0.0  # Not yet sold
        return 10000 - (.10 * self.miles)
\end{lstlisting}

Wow. That's almost identical to the car class. One of the most important rules of programming (in general, not just when dealing with objects) is "DRY" or "Don't Repeat Yourself. We've definitely repeated ourselves here. In fact, the Car and Truck classes differ only by a single character (aside from comments).

So what gives? Where did we go wrong? Our main problem is that we raced straight to the concrete: Car and Truck are real things, tangible objects that make intuitive sense as classes. However, they share so much data and functionality in common that it seems there must be an abstraction we can introduce here. Indeed there is: the notion of Vehicle.

\subsection{Abstract Classes}

A Vehicle is not a real-world object. Rather, it is a concept that some real-world objects (like cars, trucks, and motorcycles) embody. We would like to use the fact that each of these objects can be considered a vehicle to remove repeated code. We can do that by creating a Vehicle class:

\begin{lstlisting}[language=Python]
class Vehicle(object):
    base_sale_price = 0

    def __init__(self, wheels, miles, make, model, year, sold_on):
        self.wheels = wheels
        self.miles = miles
        self.make = make
        self.model = model
        self.year = year
        self.sold_on = sold_on


    def sale_price(self):
        if self.sold_on is not None:
            return 0.0  # Already sold
        return 5000.0 * self.wheels

    def purchase_price(self):
        if self.sold_on is None:
            return 0.0  # Not yet sold
        return self.base_sale_price - (.10 * self.miles)
\end{lstlisting}

Now we can make the Car and Truck class inherit from the Vehicle class by replacing object in the line class Car(object). The class in parenthesis is the class that is inherited from (object essentially means "no inheritance". We'll discuss exactly why we write that in a bit).

We can now define Car and Truck in a very straightforward way:

\begin{lstlisting}[language=Python]
class Car(Vehicle):

    def __init__(self, wheels, miles, make, model, year, sold_on):
        self.wheels = wheels
        self.miles = miles
        self.make = make
        self.model = model
        self.year = year
        self.sold_on = sold_on
        self.base_sale_price = 8000


class Truck(Vehicle):

    def __init__(self, wheels, miles, make, model, year, sold_on):
        self.wheels = wheels
        self.miles = miles
        self.make = make
        self.model = model
        self.year = year
        self.sold_on = sold_on
        self.base_sale_price = 10000
\end{lstlisting}

Object
Convert dict to object

\begin{lstlisting}[language=Python]

class Struct:
    def __init__(self, **entries):
        self.__dict__.update(entries)
\end{lstlisting}

Then, you can use

\begin{lstlisting}
> args = {'a': 1, 'b': 2}
> s = Struct(**args)
> s
< __main__.Struct instance at 0x01D6A738 >
> s.a
1
> s.b
2
\end{lstlisting}

Suggested Readings
Improve Your Python: Python Classes and Object Oriented Programming
stackoverflow, Convert Python dict to object?
Why are Python's 'private' methods not actually private?

\subsection{Design Patterns}

Design Patterns
Singleton
Non-thread-safe
Paul Manta's implementation of singletons

\begin{lstlisting}[language=Python]
@Singleton
class Foo:
   def __init__(self):
       print 'Foo created'

f = Foo() # Error, this isn't how you get the instance of a singleton

f = Foo.Instance() # Good. Being explicit is in line with the Python Zen
g = Foo.Instance() # Returns already created instance

print f is g # True

class Singleton:
    """
    A non-thread-safe helper class to ease implementing singletons.
    This should be used as a decorator -- not a metaclass -- to the
    class that should be a singleton.

    The decorated class can define one `__init__` function that
    takes only the `self` argument. Also, the decorated class cannot be
    inherited from. Other than that, there are no restrictions that apply
    to the decorated class.

    To get the singleton instance, use the `Instance` method. Trying
    to use `__call__` will result in a `TypeError` being raised.

    """

    def __init__(self, decorated):
        self._decorated = decorated

    def Instance(self):
        """
        Returns the singleton instance. Upon its first call, it creates a
        new instance of the decorated class and calls its `__init__` method.
        On all subsequent calls, the already created instance is returned.

        """
        try:
            return self._instance
        except AttributeError:
            self._instance = self._decorated()
            return self._instance

    def __call__(self):
        raise TypeError('Singletons must be accessed through `Instance()`.')

    def __instancecheck__(self, inst):
        return isinstance(inst, self._decorated)
\end{lstlisting}

Thread safe

werediver's implementation of singletons. A thread safe implementation of singleton pattern in Python. Based on tornado.ioloop.IOLoop.instance() approach.

import threading

# Based on tornado.ioloop.IOLoop.instance() approach.
# See https://github.com/facebook/tornado
class SingletonMixin(object):
    __singleton_lock = threading.Lock()
    __singleton_instance = None

    @classmethod
    def instance(cls):
        if not cls.__singleton_instance:
            with cls.__singleton_lock:
                if not cls.__singleton_instance:
                    cls.__singleton_instance = cls()
        return cls.__singleton_instance

class A(SingletonMixin):
    pass

class B(SingletonMixin):
    pass

if __name__ == '__main__':
    a, a2 = A.instance(), A.instance()
    b, b2 = B.instance(), B.instance()

    assert a is a2
    assert b is b2
    assert a is not b

    print('a:  %s\na2: %s' % (a, a2))
    print('b:  %s\nb2: %s' % (b, b2))
Suggested Readings
Is there a simple, elegant way to define singletons?

\section{File System \& IO}

\subsection{JSON}

Write json file with pretty format and unicode

\begin{lstlisting}[language=Python]
import json
import io

data = {
    "menu": {
        "header": "Sample Menu",
        "items": [
            {"id": "Open"},
            {"id": "OpenNew", "label": "Open New"},
            None,
            {"id": "Help"},
            {"id": "About", "label": "About Adobe CVG Viewer..."}
        ]
    }}

with io.open("sample_json.json", "w", encoding="utf8") as f:
    content = json.dumps(data, indent=4, sort_keys=True, ensure_ascii=False)
    f.write(unicode(content))
\end{lstlisting}

\textbf{Output}

\begin{lstlisting}
{
    "menu": {
        "header": "Sample Menu",
        "items": [
            {
                "id": "Open"
            },
            {
                "id": "OpenNew",
                "label": "Open New"
            },
            null,
            {
                "id": "Help"
            },
            {
                "id": "About",
                "label": "About Adobe CVG Viewer..."
            }
        ]
    }
}
\end{lstlisting}

\textbf{Read json file}

\begin{lstlisting}[language=Python]
import json
from pprint import pprint

with open('sample_json.json') as data_file:
    data = json.load(data_file)

pprint(data)
\end{lstlisting}


\textbf{Output}

\begin{lstlisting}[language=Python]
{u'menu': {u'header': u'Sample Menu',
           u'items': [{u'id': u'Open'},
                      {u'id': u'OpenNew', u'label': u'Open New'},
                      None,
                      {u'id': u'Help'},
                      {u'id': u'About',
                       u'label': u'About Adobe CVG Viewer...'}]}}
\end{lstlisting}

Related Reading

Parsing values from a JSON file in Python, stackoverflow
How do I write JSON data to a file in Python?, stackoverflow

\subsection{XML}

Write xml file with lxml package

\begin{lstlisting}[language=Python]
import lxml.etree as ET
# root declaration
root = ET.Element('catalog')
# insert comment
comment = ET.Comment(' this is a xml sample file ')
root.insert(1, comment)
# book element
book = ET.SubElement(root, 'book', id="bk001")
# book data
author = ET.SubElement(book, 'author')
author.text = "Gambardella, Matthew"
title = ET.SubElement(book, 'title')
title.text = "XML Developer's Guide"
# write xml to file
tree = ET.ElementTree(root)
tree.write("sample_book.xml", pretty_print=True, xml_declaration=True, encoding='utf-8')
\end{lstlisting}

\textbf{Output}

\begin{lstlisting}
<?xml version='1.0' encoding='UTF-8'?>
<catalog>
  <!-- this is a xml sample file -->
  <book id="bk001">
    <author>Gambardella, Matthew</author>
    <title>XML Developer's Guide</title>
  </book>
</catalog>
\end{lstlisting}


Read xml file with lxml package

\begin{lstlisting}[language=Python]
from lxml import etree as ET

tree = ET.parse("sample_book.xml")
root = tree.getroot()
book = root.find('book')
print "Book Information"
print "ID     :", book.attrib["id"]
print "Author :", book.find('author').text
print "Title  :", book.find('title').text
\end{lstlisting}

\textbf{Output}

\begin{lstlisting}
Book Information
ID     : bk001
Author : Gambardella, Matthew
Title  : XML Developer's Guide
\end{lstlisting}

\chapter{Python ứng dụng}

\textbf{Mục tiêu của khoá học}

Tìm hiểu các vấn đề lập trình Python nâng cao qua các ví dụ thực tế, sinh động

\textbf{Đối tượng học viên}

\begin{itemize}
  \item Là sinh viên năm 2, năm 3
  \item Đang học các môn Lập trình song song, phát triển Web
\end{itemize}

\section{Yield and Generators}

Coroutines and Subroutines
When we call a normal Python function, execution starts at function's first line and continues until a return statement, exception, or the end of the function (which is seen as an implicit return None) is encountered. Once a function returns control to its caller, that's it. Any work done by the function and stored in local variables is lost. A new call to the function creates everything from scratch.

This is all very standard when discussing functions (more generally referred to as subroutines) in computer programming. There are times, though, when it's beneficial to have the ability to create a "function" which, instead of simply returning a single value, is able to yield a series of values. To do so, such a function would need to be able to "save its work," so to speak.

I said, "yield a series of values" because our hypothetical function doesn't "return" in the normal sense. return implies that the function is returning control of execution to the point where the function was called. "Yield," however, implies that the transfer of control is temporary and voluntary, and our function expects to regain it in the future.

In Python, "functions" with these capabilities are called generators, and they're incredibly useful. generators (and the yield statement) were initially introduced to give programmers a more straightforward way to write code responsible for producing a series of values. Previously, creating something like a random number generator required a class or module that both generated values and kept track of state between calls. With the introduction of generators, this became much simpler.

To better understand the problem generators solve, let's take a look at an example. Throughout the example, keep in mind the core problem being solved: generating a series of values.

Note: Outside of Python, all but the simplest generators would be referred to as coroutines. I'll use the latter term later in the post. The important thing to remember is, in Python, everything described here as a coroutine is still a generator. Python formally defines the term generator; coroutine is used in discussion but has no formal definition in the language.

Example: Fun With Prime Numbers
Suppose our boss asks us to write a function that takes a list of ints and returns some Iterable containing the elements which are prime1 numbers.

Remember, an Iterable is just an object capable of returning its members one at a time.

"Simple," we say, and we write the following:

\begin{lstlisting}[language=Python]
def get_primes(input_list):
    result_list = list()
    for element in input_list:
        if is_prime(element):
            result_list.append()

    return result_list
\end{lstlisting}

or better yet...

\begin{lstlisting}[language=Python]
def get_primes(input_list):
    return (element for element in input_list if is_prime(element))

# not germane to the example, but here's a possible implementation of
# is_prime...

def is_prime(number):
    if number > 1:
        if number == 2:
            return True
        if number % 2 == 0:
            return False
        for current in range(3, int(math.sqrt(number) + 1), 2):
            if number % current == 0:
                return False
        return True
    return False
\end{lstlisting}

Either get_primes implementation above fulfills the requirements, so we tell our boss we're done. She reports our function works and is exactly what she wanted.

Dealing With Infinite Sequences
Well, not quite exactly. A few days later, our boss comes back and tells us she's run into a small problem: she wants to use our get_primes function on a very large list of numbers. In fact, the list is so large that merely creating it would consume all of the system's memory. To work around this, she wants to be able to call get_primes with a start value and get all the primes larger than start (perhaps she's solving Project Euler problem 10).

Once we think about this new requirement, it becomes clear that it requires more than a simple change to get_primes. Clearly, we can't return a list of all the prime numbers from start to infinity (operating on infinite sequences, though, has a wide range of useful applications). The chances of solving this problem using a normal function seem bleak.

Before we give up, let's determine the core obstacle preventing us from writing a function that satisfies our boss's new requirements. Thinking about it, we arrive at the following: functions only get one chance to return results, and thus must return all results at once. It seems pointless to make such an obvious statement; "functions just work that way," we think. The real value lies in asking, "but what if they didn't?"

Imagine what we could do if get_primes could simply return the next value instead of all the values at once. It wouldn't need to create a list at all. No list, no memory issues. Since our boss told us she's just iterating over the results, she wouldn't know the difference.

Unfortunately, this doesn't seem possible. Even if we had a magical function that allowed us to iterate from n to infinity, we'd get stuck after returning the first value:

def get_primes(start):
    for element in magical_infinite_range(start):
        if is_prime(element):
            return element
Imagine get_primes is called like so:

def solve_number_10():
    # She *is* working on Project Euler #10, I knew it!
    total = 2
    for next_prime in get_primes(3):
        if next_prime < 2000000:
            total += next_prime
        else:
            print(total)
            return
Clearly, in get_primes, we would immediately hit the case where number = 3 and return at line 4. Instead of return, we need a way to generate a value and, when asked for the next one, pick up where we left off.

Functions, though, can't do this. When they return, they're done for good. Even if we could guarantee a function would be called again, we have no way of saying, "OK, now, instead of starting at the first line like we normally do, start up where we left off at line 4." Functions have a single entry point: the first line.

Enter the Generator
This sort of problem is so common that a new construct was added to Python to solve it: the generator. A generator "generates" values. Creating generators was made as straightforward as possible through the concept of generator functions, introduced simultaneously.

A generator function is defined like a normal function, but whenever it needs to generate a value, it does so with the yield keyword rather than return. If the body of a def contains yield, the function automatically becomes a generator function (even if it also contains a return statement). There's nothing else we need to do to create one.

generator functions create generator iterators. That's the last time you'll see the term generator iterator, though, since they're almost always referred to as "generators". Just remember that a generator is a special type of iterator. To be considered an iterator, generators must define a few methods, one of which is next(). To get the next value from a generator, we use the same built-in function as for iterators: next().

This point bears repeating: to get the next value from a generator, we use the same built-in function as for iterators: next().

(next() takes care of calling the generator's next() method). Since a generator is a type of iterator, it can be used in a for loop.

So whenever next() is called on a generator, the generator is responsible for passing back a value to whomever called next(). It does so by calling yield along with the value to be passed back (e.g. yield 7). The easiest way to remember what yield does is to think of it as return (plus a little magic) for generator functions.**

Again, this bears repeating: yield is just return (plus a little magic) for generator functions.

Here's a simple generator function:

>>> def simple_generator_function():
>>>    yield 1
>>>    yield 2
>>>    yield 3
And here are two simple ways to use it:

>>> for value in simple_generator_function():
>>>     print(value)
1
2
3
>>> our_generator = simple_generator_function()
>>> next(our_generator)
1
>>> next(our_generator)
2
>>> next(our_generator)
3
Magic?
What's the magic part? Glad you asked! When a generator function calls yield, the "state" of the generator function is frozen; the values of all variables are saved and the next line of code to be executed is recorded until next() is called again. Once it is, the generator function simply resumes where it left off. If next() is never called again, the state recorded during the yield call is (eventually) discarded.

Let's rewrite get_primes as a generator function. Notice that we no longer need the magical_infinite_range function. Using a simple while loop, we can create our own infinite sequence:

def get_primes(number):
    while True:
        if is_prime(number):
            yield number
        number += 1
If a generator function calls return or reaches the end its definition, a StopIteration exception is raised. This signals to whoever was calling next() that the generator is exhausted (this is normal iterator behavior). It is also the reason the while True: loop is present in get_primes. If it weren't, the first time next() was called we would check if the number is prime and possibly yield it. If next() were called again, we would uselessly add 1 to number and hit the end of the generator function (causing StopIteration to be raised). Once a generator has been exhausted, calling next() on it will result in an error, so you can only consume all the values of a generator once. The following will not work:

>>> our_generator = simple_generator_function()
>>> for value in our_generator:
>>>     print(value)

>>> # our_generator has been exhausted...
>>> print(next(our_generator))
Traceback (most recent call last):
  File "<ipython-input-13-7e48a609051a>", line 1, in <module>
    next(our_generator)
StopIteration

>>> # however, we can always create a new generator
>>> # by calling the generator function again...

>>> new_generator = simple_generator_function()
>>> print(next(new_generator)) # perfectly valid
1
Thus, the while loop is there to make sure we never reach the end of get_primes. It allows us to generate a value for as long as next() is called on the generator. This is a common idiom when dealing with infinite series (and generators in general).

Visualizing the flow
Let's go back to the code that was calling get_primes: solve_number_10.

def solve_number_10():
    # She *is* working on Project Euler #10, I knew it!
    total = 2
    for next_prime in get_primes(3):
        if next_prime < 2000000:
            total += next_prime
        else:
            print(total)
            return
It's helpful to visualize how the first few elements are created when we call get_primes in solve_number_10's for loop. When the for loop requests the first value from get_primes, we enter get_primes as we would in a normal function.

We enter the while loop on line 3
The if condition holds (3 is prime)
We yield the value 3 and control to solve_number_10.
Then, back in solve_number_10:

The value 3 is passed back to the for loop
The for loop assigns next_prime to this value
next_prime is added to total
The for loop requests the next element from get_primes
This time, though, instead of entering get_primes back at the top, we resume at line 5, where we left off.

def get_primes(number):
    while True:
        if is_prime(number):
            yield number
        number += 1 # <<<<<<<<<<
Most importantly, number still has the same value it did when we called yield (i.e. 3). Remember, yield both passes a value to whoever called next(), and saves the "state" of the generator function. Clearly, then, number is incremented to 4, we hit the top of the while loop, and keep incrementing number until we hit the next prime number (5). Again we yield the value of number to the for loop in solve_number_10. This cycle continues until the for loop stops (at the first prime greater than 2,000,000).

Moar Power
In PEP 342, support was added for passing values into generators. PEP 342 gave generators the power to yield a value (as before), receive a value, or both yield a value and receive a (possibly different) value in a single statement.

To illustrate how values are sent to a generator, let's return to our prime number example. This time, instead of simply printing every prime number greater than number, we'll find the smallest prime number greater than successive powers of a number (i.e. for 10, we want the smallest prime greater than 10, then 100, then 1000, etc.). We start in the same way as get_primes:

def print_successive_primes(iterations, base=10):
    # like normal functions, a generator function
    # can be assigned to a variable

    prime_generator = get_primes(base)
    # missing code...
    for power in range(iterations):
        # missing code...

def get_primes(number):
    while True:
        if is_prime(number):
        # ... what goes here?
The next line of get_primes takes a bit of explanation. While yield number would yield the value of number, a statement of the form other = yield foo means, "yield foo and, when a value is sent to me, set other to that value." You can "send" values to a generator using the generator's send method.

def get_primes(number):
    while True:
        if is_prime(number):
            number = yield number
        number += 1
In this way, we can set number to a different value each time the generator yields. We can now fill in the missing code in print_successive_primes:

def print_successive_primes(iterations, base=10):
    prime_generator = get_primes(base)
    prime_generator.send(None)
    for power in range(iterations):
        print(prime_generator.send(base ** power))
Two things to note here: First, we're printing the result of generator.send, which is possible because send both sends a value to the generator and returns the value yielded by the generator (mirroring how yield works from within the generator function).

Second, notice the prime_generator.send(None) line. When you're using send to "start" a generator (that is, execute the code from the first line of the generator function up to the first yield statement), you must send None. This makes sense, since by definition the generator hasn't gotten to the first yield statement yet, so if we sent a real value there would be nothing to "receive" it. Once the generator is started, we can send values as we do above.

Round-up
In the second half of this series, we'll discuss the various ways in which generators have been enhanced and the power they gained as a result. yield has become one of the most powerful keywords in Python. Now that we've built a solid understanding of how yield works, we have the knowledge necessary to understand some of the more "mind-bending" things that yield can be used for.

Believe it or not, we've barely scratched the surface of the power of yield. For example, while send does work as described above, it's almost never used when generating simple sequences like our example. Below, I've pasted a small demonstration of one common way send is used. I'll not say any more about it as figuring out how and why it works will be a good warm-up for part two.

\begin{lstlisting}[language=Python]
import random

def get_data():
    """Return 3 random integers between 0 and 9"""
    return random.sample(range(10), 3)

def consume():
    """Displays a running average across lists of integers sent to it"""
    running_sum = 0
    data_items_seen = 0

    while True:
        data = yield
        data_items_seen += len(data)
        running_sum += sum(data)
        print('The running average is {}'.format(running_sum / float(data_items_seen)))

def produce(consumer):
    """Produces a set of values and forwards them to the pre-defined consumer
    function"""
    while True:
        data = get_data()
        print('Produced {}'.format(data))
        consumer.send(data)
        yield

if __name__ == '__main__':
    consumer = consume()
    consumer.send(None)
    producer = produce(consumer)

    for _ in range(10):
        print('Producing...')
        next(producer)
\end{lstlisting}

Remember...
There are a few key ideas I hope you take away from this discussion:

generators are used to generate a series of values
yield is like the return of generator functions
The only other thing yield does is save the "state" of a generator function
A generator is just a special type of iterator
Like iterators, we can get the next value from a generator using next()
for gets values by calling next() implicitly

\subsection{Metaclasses}

Metaclasses
Python, Classes, and Objects
Most readers are aware that Python is an object-oriented language. By object-oriented, we mean that Python can define classes, which bundle data and functionality into one entity. For example, we may create a class IntContainer which stores an integer and allows certain operations to be performed:

\begin{lstlisting}[language=Python]
class IntContainer(object):
    def __init__(self, i):
        self.i = int(i)

    def add_one(self):
        self.i += 1
ic = IntContainer(2)
ic.add_one()
print(ic.i)
3
\end{lstlisting}

This is a bit of a silly example, but shows the fundamental nature of classes: their ability to bundle data and operations into a single object, which leads to cleaner, more manageable, and more adaptable code. Additionally, classes can inherit properties from parents and add or specialize attributes and methods. This object-oriented approach to programming can be very intuitive and powerful.

What many do not realize, though, is that quite literally everything in the Python language is an object.

For example, integers are simply instances of the built-in int type:

print type(1)
<type 'int'>
To emphasize that the int type really is an object, let's derive from it and specialize the __add__ method (which is the machinery underneath the + operator):

(Note: We'll used the super syntax to call methods from the parent class: if you're unfamiliar with this, take a look at this StackOverflow question).

\begin{lstlisting}[language=Python]
class MyInt(int):
    def __add__(self, other):
        print "specializing addition"
        return super(MyInt, self).__add__(other)

i = MyInt(2)
print(i + 2)
specializing addition
4
\end{lstlisting}

Using the + operator on our derived type goes through our __add__ method, as expected. We see that int really is an object that can be subclassed and extended just like user-defined classes. The same is true of floats, lists, tuples, and everything else in the Python language. They're all objects.

Down the Rabbit Hole: Classes as Objects
We said above that everything in python is an object: it turns out that this is true of classes themselves. Let's look at an example.

We'll start by defining a class that does nothing

class DoNothing(object):
    pass
If we instantiate this, we can use the type operator to see the type of object that it is:

d = DoNothing()
type(d)
__main__.DoNothing
We see that our variable d is an instance of the class __main__.DoNothing.

We can do this similarly for built-in types:

L = [1, 2, 3]
type(L)
list
A list is, as you may expect, an object of type list.

But let's take this a step further: what is the type of DoNothing itself?

type(DoNothing)
type
The type of DoNothing is type. This tells us that the class DoNothing is itself an object, and that object is of type type.

It turns out that this is the same for built-in datatypes:

type(tuple), type(list), type(int), type(float)
(type, type, type, type)
What this shows is that in Python, classes are objects, and they are objects of type type.  type is a metaclass: a class which instantiates classes. All new-style classes in Python are instances of the type metaclass, including type itself:

type(type)
type
Yes, you read that correctly: the type of type is type. In other words, type is an instance of itself. This sort of circularity cannot (to my knowledge) be duplicated in pure Python, and the behavior is created through a bit of a hack at the implementation level of Python.

Metaprogramming: Creating Classes on the Fly
Now that we've stepped back and considered the fact that classes in Python are simply objects like everything else, we can think about what is known as metaprogramming. You're probably used to creating functions which return objects. We can think of these functions as an object factory: they take some arguments, create an object, and return it. Here is a simple example of a function which creates an int object:

def int_factory(s):
    i = int(s)
    return i

i = int_factory('100')
print(i)
100
This is overly-simplistic, but any function you write in the course of a normal program can be boiled down to this: take some arguments, do some operations, and create & return an object. With the above discussion in mind, though, there's nothing to stop us from creating an object of type type (that is, a class), and returning that instead -- this is a metafunction:

def class_factory():
    class Foo(object):
        pass
    return Foo

F = class_factory()
f = F()
print(type(f))
<class '__main__.Foo'>
Just as the function int_factory constructs an returns an instance of int, the function class_factory constructs and returns an instance of type: that is, a class.

But the above construction is a bit awkward: especially if we were going to do some more complicated logic when constructing Foo, it would be nice to avoid all the nested indentations and define the class in a more dynamic way. We can accomplish this by instantiating Foo from type directly:

def class_factory():
    return type('Foo', (), {})

F = class_factory()
f = F()
print(type(f))
<class '__main__.Foo'>
In fact, the construct

class MyClass(object):
    pass
is identical to the construct

MyClass = type('MyClass', (), {})
MyClass is an instance of type type, and that can be seen explicitly in the second version of the definition. A potential confusion arises from the more common use of type as a function to determine the type of an object, but you should strive to separate these two uses of the keyword in your mind: here type is a class (more precisely, a metaclass), and MyClass is an instance of type.

The arguments to the type constructor are: type(name, bases, dct) - name is a string giving the name of the class to be constructed - bases is a tuple giving the parent classes of the class to be constructed - dct is a dictionary of the attributes and methods of the class to be constructed

So, for example, the following two pieces of code have identical results:

class Foo(object):
    i = 4

class Bar(Foo):
    def get_i(self):
        return self.i

b = Bar()
print(b.get_i())
4
Foo = type('Foo', (), dict(i=4))

Bar = type('Bar', (Foo,), dict(get_i = lambda self: self.i))

b = Bar()
print(b.get_i())
4
This perhaps seems a bit over-complicated in the case of this contrived example, but it can be very powerful as a means of dynamically creating new classes on-the-fly.

Making Things Interesting: Custom Metaclasses
Now things get really fun. Just as we can inherit from and extend a class we've created, we can also inherit from and extend the type metaclass, and create custom behavior in our metaclass.

Example 1: Modifying Attributes
Let's use a simple example where we want to create an API in which the user can create a set of interfaces which contain a file object. Each interface should have a unique string ID, and contain an open file object. The user could then write specialized methods to accomplish certain tasks. There are certainly good ways to do this without delving into metaclasses, but such a simple example will (hopefully) elucidate what's going on.

First we'll create our interface meta class, deriving from type:

class InterfaceMeta(type):
    def __new__(cls, name, parents, dct):
        # create a class_id if it's not specified
        if 'class_id' not in dct:
            dct['class_id'] = name.lower()

        # open the specified file for writing
        if 'file' in dct:
            filename = dct['file']
            dct['file'] = open(filename, 'w')

        # we need to call type.__new__ to complete the initialization
        return super(InterfaceMeta, cls).__new__(cls, name, parents, dct)
Notice that we've modified the input dictionary (the attributes and methods of the class) to add a class id if it's not present, and to replace the filename with a file object pointing to that file name.

Now we'll use our InterfaceMeta class to construct and instantiate an Interface object:

Interface = InterfaceMeta('Interface', (), dict(file='tmp.txt'))

print(Interface.class_id)
print(Interface.file)
interface
<open file 'tmp.txt', mode 'w' at 0x21b8810>
This behaves as we'd expect: the class_id class variable is created, and the file class variable is replaced with an open file object. Still, the creation of the Interface class using InterfaceMeta directly is a bit clunky and difficult to read. This is where __metaclass__ comes in and steals the show. We can accomplish the same thing by defining Interface this way:

class Interface(object):
    __metaclass__ = InterfaceMeta
    file = 'tmp.txt'

print(Interface.class_id)
print(Interface.file)
interface
<open file 'tmp.txt', mode 'w' at 0x21b8ae0>
by defining the __metaclass__ attribute of the class, we've told the class that it should be constructed using InterfaceMeta rather than using type. To make this more definite, observe that the type of Interface is now InterfaceMeta:

type(Interface)
__main__.InterfaceMeta
Furthermore, any class derived from Interface will now be constructed using the same metaclass:

class UserInterface(Interface):
    file = 'foo.txt'

print(UserInterface.file)
print(UserInterface.class_id)
<open file 'foo.txt', mode 'w' at 0x21b8c00>
userinterface
This simple example shows how metaclasses can be used to create powerful and flexible APIs for projects. For example, the Django project makes use of these sorts of constructions to allow concise declarations of very powerful extensions to their basic classes.

Example 2: Registering Subclasses
Another possible use of a metaclass is to automatically register all subclasses derived from a given base class. For example, you may have a basic interface to a database and wish for the user to be able to define their own interfaces, which are automatically stored in a master registry.

You might proceed this way:

class DBInterfaceMeta(type):
    # we use __init__ rather than __new__ here because we want
    # to modify attributes of the class *after* they have been
    # created
    def __init__(cls, name, bases, dct):
        if not hasattr(cls, 'registry'):
            # this is the base class.  Create an empty registry
            cls.registry = {}
        else:
            # this is a derived class.  Add cls to the registry
            interface_id = name.lower()
            cls.registry[interface_id] = cls

        super(DBInterfaceMeta, cls).__init__(name, bases, dct)
Our metaclass simply adds a registry dictionary if it's not already present, and adds the new class to the registry if the registry is already there. Let's see how this works:

class DBInterface(object):
    __metaclass__ = DBInterfaceMeta

print(DBInterface.registry)
{}
Now let's create some subclasses, and double-check that they're added to the registry:

class FirstInterface(DBInterface):
    pass

class SecondInterface(DBInterface):
    pass

class SecondInterfaceModified(SecondInterface):
    pass

print(DBInterface.registry)
{'firstinterface': <class '__main__.FirstInterface'>, 'secondinterface': <class '__main__.SecondInterface'>, 'secondinterfacemodified': <class '__main__.SecondInterfaceModified'>}
It works as expected! This could be used in conjunction with a function that chooses implementations from the registry, and any user-defined Interface-derived objects would be automatically accounted for, without the user having to remember to manually register the new types.

Conclusion: When Should You Use Metaclasses?
I've gone through some examples of what metaclasses are, and some ideas about how they might be used to create very powerful and flexible APIs. Although metaclasses are in the background of everything you do in Python, the average coder rarely has to think about them.

But the question remains: when should you think about using custom metaclasses in your project? It's a complicated question, but there's a quotation floating around the web that addresses it quite succinctly:

Metaclasses are deeper magic than 99\% of users should ever worry about. If you wonder whether you need them, you don't (the people who actually need them know with certainty that they need them, and don't need an explanation about why).

Tim Peters

In a way, this is a very unsatisfying answer: it's a bit reminiscent of the wistful and cliched explanation of the border between attraction and love: "well, you just... know!"

But I think Tim is right: in general, I've found that most tasks in Python that can be accomplished through use of custom metaclasses can also be accomplished more cleanly and with more clarity by other means. As programmers, we should always be careful to avoid being clever for the sake of cleverness alone, though it is admittedly an ever-present temptation.

I personally spent six years doing science with Python, writing code nearly on a daily basis, before I found a problem for which metaclasses were the natural solution. And it turns out Tim was right:

I just knew.

\section{Hệ điều hành}

\subsection{File Operations}

\textbf{Copy folder}

\begin{lstlisting}[language=Python]
import shutil
shutil.copyfile("src", "dst")
\end{lstlisting}


\subsection{CLI}

shutil - High-level file operations

\section{Cơ sở dữ liệu (chưa xây dựng)}

\section{Giao diện (chưa xây dựng)}

\section{Lập trình mạng}


REST
JSON 1 2
GET

\begin{lstlisting}[language=Python]
import requests
url = "http://localhost:8080/messages"
response = requests.get(url)
data = response.json()
\end{lstlisting}

\textbf{POST}

\begin{lstlisting}[language=Python]
import requests
import json

url = "http://localhost:8080/messages"
data = {'sender': 'Alice', 'receiver': 'Bob', 'message': 'Hello!'}
headers = {
  'Content-type': 'application/json',
  'Accept': 'application/json'}
r = requests.post(url, data=json.dumps(data), headers=headers)
\end{lstlisting}

\chapter{Phát triển phần mềm với Python}

\subsection{Mục tiêu của khóa học}

\subsection{Đối tượng học viên}

\begin{itemize}
  \item Đã lập trình Python được 1-2 năm
  \item Muốn phát triển phần mềm mã nguồn mở
\end{itemize}

\section{Logging}

levels, attributes references

The logging library takes a modular approach and offers several categories of components: loggers, handlers, filters, and formatters.

Loggers expose the interface that application code directly uses.
Handlers send the log records (created by loggers) to the appropriate destination.
Filters provide a finer grained facility for determining which log records to output.
Formatters specify the layout of log records in the final output.
Step 0: Project structure

\begin{lstlisting}
code/
├── main.py
├── config
├   └── logging.conf
└── logs
    └── app.log
\end{lstlisting}

Step 1: Create file logging.conf

[loggers]
keys=root

[handlers]
keys=consoleHandler,fileHandler

[formatters]
keys=formatter

[logger_root]
level=DEBUG
handlers=consoleHandler,fileHandler

[handler_consoleHandler]
class=StreamHandler
level=DEBUG
formatter=formatter
args=(sys.stdout,)

[handler_fileHandler]
class=FileHandler
level=DEBUG
formatter=formatter
args = ('logs/app.log','a')

[formatter_formatter]
format=%(asctime)s - %(name)s - %(levelname)s - %(message)s
datefmt=
Step 2: Load config and create logger

In main.py

import logging.config

# load logging config
logging.config.fileConfig('config/logging.conf')
Step 3: In your application code

logging.getLogger().debug('debug message')
logging.getLogger().info('info message')
logging.getLogger().warn('warn message')
logging.getLogger().error('error message')
logging.getLogger().critical('critical message')
More Resources

Introduction to Logging
Quick and simple usage of python log
Python: Logging module ↩

Python: Logging cookbook ↩

Python: Logging guide ↩

\section{Configuration}

pyconfiguration

Installation
conda install -c rain1024 pyconfiguration
Usage
Step 1: Create config.json file

{
  "SERVICE_URL": "http://api.service.com"
}
Step 2: Add these code to main.py file

from pyconfiguration import Configuration
Configuration.load('config.json')
print Configuration.SERVICE_URL

> http://api.service.com
References: What's the best practice using a settings file 1

What's the best practice using a settings file in Python? ↩

\section{Command Line}

Command Line Arguments
There are the following modules in the standard library:

The getopt module is similar to GNU getopt.
The optparse module offers object-oriented command line option parsing.
Here is an example that uses the latter from the docs:

from optparse import OptionParser

parser = OptionParser()
parser.add_option("-f", "--file", dest="filename",
                  help="write report to FILE", metavar="FILE")
parser.add_option("-q", "--quiet",
                  action="store_false", dest="verbose", default=True,
                  help="don't print status messages to stdout")

(options, args) = parser.parse_args()
optparse supports (among other things):

Multiple options in any order.
Short and long options.
Default values.
Generation of a usage help message.
Suggest Reading
Command Line Arguments In Python

\section{Testing}

Testing your code is very important.

Getting used to writing testing code and running this code in parallel is now considered a good habit. Used wisely, this method helps you define more precisely your code’s intent and have a more decoupled architecture.

Unittest
unittest is the batteries-included test module in the Python standard library. Its API will be familiar to anyone who has used any of the JUnit/nUnit/CppUnit series of tools.

The Basics
Creating test cases is accomplished by subclassing unittest.TestCase.

import unittest

def fun(x):
    return x + 1

class MyTest(unittest.TestCase):
    def test(self):
        self.assertEqual(fun(3), 4)
Skipping tests
Unittest supports skipping individual test methods and even whole classes of tests. In addition, it supports marking a test as an “expected failure,” a test that is broken and will fail, but shouldn’t be counted as a failure on a .code TestResult.

Skipping a test is simply a matter of using the skip() decorator or one of its conditional variants.

import sys
import unittest

class MyTestCase(unittest.TestCase):

    @unittest.skip("demonstrating skipping")
    def test_nothing(self):
        self.fail("shouldn't happen")

    @unittest.skipIf(mylib.__version__ < (1, 3),
                     "not supported in this library version")
    def test_format(self):
        # Tests that work for only a certain version of the library.
        pass

    @unittest.skipUnless(sys.platform.startswith("win"), "requires Windows")
    def test_windows_support(self):
        # windows specific testing code
        pass
Tox
tox aims to automate and standardize testing in Python. It is part of a larger vision of easing the packaging, testing and release process of Python software.

Tox is a generic virtualenv management and test command line tool you can use for:

checking your package installs correctly with different Python versions and interpreters
running your tests in each of the environments, configuring your test tool of choice
acting as a frontend to Continuous Integration servers, greatly reducing boilerplate and merging CI and shell-based testing.
Installation

You can install tox with pip using the following command

\begin{lstlisting}[language=bash]
> pip install tox
\end{lstlisting}

Setup default environment in Windows with conda

\begin{lstlisting}[language=bash]
> conda create -p C:\python27 python=2.7
> conda create -p C:\python34 python=3.4
\end{lstlisting}

Related Readings
Testing Your Code, The Hitchhiker's Guide to Python
unittest  Unit testing framework, docs.python.org
Is it possible to use tox with conda-based Python installations?, stackoverflow

\section{IDE \& Debugging}

Today, I write some notes about my favorite Python IDE - PyCharm. I believe it's a good one for developing python, which supports git, vim, etc. This list below contains my favorite features.

Pycharm Features
Intelligent Editor
Navigation
Graphical Debugger
Refactorings
Code Inspections
Version Control Integration
Scientific Tools
Intelligent Editor
PyCharm provides smart code completion, code inspections, on-the-fly error highlighting and quick-fixes, along with automated code refactorings and rich navigation capabilities.

Syntax Highlighting

Read your code easier with customizable colors for Python code and Django templates. Choose from several predefined color themes.

Auto-Identation and code formating

Automatic indents are inserted on new line. Indent verification and code re-formatting are compliant with project code-style settings.

Configurable code styles

Select a predefined coding style to apply to your code style configuration for various supported languages.

Code completion

Code completion for keywords, classes, variables, etc. as you type or via Ctrl+Space. Editor suggestions are context-aware and offer the most appropriate options.

Keyboard shortcuts: Tab, Alt+Enter

Code selection and comments

Select a block of code and expand it to an expression, to a line, to a logical block of code, and so on with shortcuts. Single keystroke to comment/uncomment the current line or selection.

Code formatter

Code formatter with code style configuration and other features help you write neat code that's easy to support. PyCharm contains built-in PEP-8 for Python and other standards compliant code formatting for supported languages.

Code snippets and templates

Save time using advanced customizable and parametrized live code templates and snippets.

Keyboard shortcuts check.if ENTER

if check:
  type_something
Code folding

Code folding, auto-insertion of braces, brackets & quotes, matching brace/bracket highlighting, etc.

On-the-fly error highlighting

Errors are shown as you type. The integrated spell-checker verifies your identifiers and comments for misspellings.

Multiple carets and selections

With multiple carets, you can edit several locations in your file at the same time.

Keyboard shortcuts: SHIFT + F6

Code analysis

Numerous code inspections verify Python code as you type and also allow inspecting the whole project for possible errors or code smells.

Quick-fixes

Quick-fixes for most inspections make it easy to fix or improve the code instantly. Alt+Enter shows appropriate options for each inspection.

Keyboard shortcuts: F2

Duplicated code detector

Smart duplicated code detector analyzes your code and searches for copy/pasted code. You'll be presented with a list of candidates for refactoring and with the help of refactorings it's easy to keep your code dry.

Configurable language injections

Natively edit non-Python code embedded into string literals, with code completion, error-highlighting, and other coding assistance features.

Code auto generation

Code auto-generation from usage with quick-fixes; docstrings and the code matching verification, plus autoupdate on refactoring. Automatic generation of a docstring stub (reStructuredText, Epytext, Google, and NumPy).

Intention actions

Intention actions help you apply automated changes to code that is correct, to improve it or to make your coding routine easier.

Searching

Keyboard shortcuts: Double Shift (search everywhere)

Navigation
Shortcuts

Keyboard shortcuts: ALT + SHIFT + UP/DOWN (move line up and down)

Graphical Debugger
PyCharm provides extensive options for debugging your Python/Django and JavaScript code:

Set breakpoints right inside the editor and define hit conditions
Inspect context-relevant local variables and user-defined watches, including arrays and complex objects, and edit values on the fly
Set up remote debugging using remote interpreters
Evaluate an expression in runtime and collect run-time type statistics for better autocompletion and code inspections
Attach to a running process
Debug Django templates


Inline Debugger

With an inline debugger, all live debugging data are shown directly in the editor, with variable values integrated into the editor's look-and-feel. Variable values can be viewed in the source code, right next to their usages.

Step into My Code

Use Step into My Code to stay focused on your code: the debugger will only step through your code bypassing any library sources.

Multi-process debugging

PyCharm can debug applications that spawn multiple Python processes, such as Django applications that don't run in --no-reload mode, or applications using many other Web frameworks that use a similar approach to code auto-reloading.

Run/Debug configurations

Every script/test or debugger execution creates a special 'Run/Debug Configuration' that can be edited and used later. Run/Debug Configurations can be shared with project settings for use by the whole team.

Workspace
Custom Scheme
Go to File - Settings... then Editor - Colors Fonts

Now you can change your scheme, I like Darcular

https://confluence.jetbrains.com/download/attachments/51945983/appearance3.png?version=1&modificationDate=1372843959000

IPython Support
PyCharm supports usage of IPython magic commands.

http://i.stack.imgur.com/aTEW2.png

Vim Support
You can configure PyCharm to work as a Vim editor

https://confluence.jetbrains.com/download/attachments/51946537/vim4.png?version=1&modificationDate=1370956971000

Keyboard Shortcuts: Ctrl+Shift+V (paste)

\subsection{Pycharm Pycharm}

\diary{01/2018: Pycharm là trình duyệt ưa thích của mình trong suốt 3 năm vừa rồi.}

Hôm nay tự nhiên lại gặp lỗi không tự nhận unittest, không resolve được package import bởi relative path. Vụ không tự nhận unittest sửa bằng cách xóa file .idea là xong. Còn vụ không resolve được package import bởi relative path thì vẫn chịu rồi. Nhìn code cứ đỏ lòm khó chịu thật.

\section{Package Manager}

\subsection{py2exe}

py2exe is a Python Distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation.Spice

Installation
\begin{lstlisting}[language=bash]
# py2exe
conda install -c https://conda.anaconda.org/clinicalgraphics cg-py2exe
Build 1
python setup.py py2exe
# build PyQT
python setup.py py2exe --includes sip
\end{lstlisting}

\textbf{Known Issues}

Error: Microsoft Visual C++ 10.0 is required (Unable to find vcvarsall.bat) (link)

How to fix


Step 1: Install Visual Studio 2015

Step 2:

\begin{lstlisting}[language=bash]
set VS100COMNTOOLS=\%VS140COMNTOOLS\%
\end{lstlisting}

\subsection{Quản lý gói với Anaconda}

\noindent Cài đặt package tại một branch của một project trên github

\begin{lstlisting}[language=Python]
> pip install git+https://github.com/tangentlabs/django-oscar-paypal.git@issue/34/oscar-0.6#egg=django-oscar-paypal
\end{lstlisting}

\noindent Trích xuất danh sách package

\begin{lstlisting}
> pip freeze > requirements.txt
\end{lstlisting}

\noindent \textbf{Chạy ipython trong environment anaconda}

\noindent Chạy đống lệnh này

\begin{lstlisting}[language=bash]
  conda install nb_conda
  source activate my_env
  python -m IPython kernelspec install-self --user
  ipython notebook
\end{lstlisting}

\noindent \textbf{Interactive programming với ipython}

\noindent Trích xuất ipython ra slide (không hiểu sao default `--to slides` không work nữa, lại phải thêm tham số `--reveal-prefix` \footnote{\href{https://github.com/jupyter/nbconvert/issues/91#issuecomment-283736634}{https://github.com/jupyter/nbconvert/issues/91#issuecomment-283736634}}

\begin{lstlisting}[language=bash]
jupyter nbconvert "file.ipynb"
  --to slides
  --reveal-prefix "https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.1.0"
\end{lstlisting}

**Tham khảo thêm**

* https://stackoverflow.com/questions/37085665/in-which-conda-environment-is-jupyter-executing
* https://github.com/jupyter/notebook/issues/541#issuecomment-146387578
* https://stackoverflow.com/a/20101940/772391
\section{Environment}

Similar to pip, conda is an open source package and environment management system 1. Anaconda is a data science platform that comes with a lot of packages. It uses conda at the core. Unlike Anaconda, Miniconda doesn't come with any installed packages by default. Note that for miniconda, everytime you open up a terminal, conda won't automatically be available. Run the command below to use conda within miniconda.

Conda
Let's first start by checking if conda is installed.

\begin{lstlisting}[language=bash]
> conda --version

conda 4.2.12
To see the full documentation for any command, type the command followed by --help. For example, to learn about the conda update command:
\end{lstlisting}


\begin{lstlisting}[language=bash]
> conda update --help
Once it has been confirmed that conda has been installed, we will now make sure that it is up to date.

> conda update conda

Using Anaconda Cloud api site https://api.anaconda.org
Fetching package metadata: ....
.Solving package specifications: .........

Package plan for installation in environment //anaconda:

The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    conda-env-2.6.0            |                0          601 B
    ruamel_yaml-0.11.14        |           py27_0         184 KB
    conda-4.2.12               |           py27_0         376 KB
    ------------------------------------------------------------
                                           Total:         560 KB

The following NEW packages will be INSTALLED:

    ruamel_yaml: 0.11.14-py27_0

The following packages will be UPDATED:

    conda:       4.0.7-py27_0 --> 4.2.12-py27_0
    conda-env:   2.4.5-py27_0 --> 2.6.0-0
    python:      2.7.11-0     --> 2.7.12-1
    sqlite:      3.9.2-0      --> 3.13.0-0

Proceed ([y]/n)? y

Fetching packages ...
conda-env-2.6. 100% |################################| Time: 0:00:00 360.78 kB/s
ruamel_yaml-0. 100% |################################| Time: 0:00:00   5.53 MB/s
conda-4.2.12-p 100% |################################| Time: 0:00:00   5.84 MB/s
Extracting packages ...
[      COMPLETE      ]|###################################################| 100%
Unlinking packages ...
[      COMPLETE      ]|###################################################| 100%
Linking packages ...
[      COMPLETE      ]|###################################################| 100%
Environments
\end{lstlisting}



\subsection{Create}

In order to manage environments, we need to create at least two so you can move or switch between them. To create a new environment, use the conda create command, followed by any name you wish to call it:

\begin{lstlisting}[language=Bash]
# create new environment
conda create -n <your_environment> python=2.7.11
\end{lstlisting}

\subsection{Clone}

Make an exact copy of an environment by creating a clone of it. Here we will clone snowflakes to create an exact copy named flowers:

\begin{lstlisting}[language=bash]
conda create --name flowers --clone snowflakes
\end{lstlisting}

\subsection{List}

List all environments

Now you can use conda to see which environments you have installed so far. Use the conda environment info command to find out

\begin{lstlisting}[language=bash]
> conda info -e

conda environments:
snowflakes            /home/username/miniconda/envs/snowflakes
bunnies               /home/username/miniconda/envs/bunnies
\end{lstlisting}

Verify current environment

Which environment are you using right now - snowflakes or bunnies? To find out, type the command:

\begin{lstlisting}[language=bash]
conda info --envs
\end{lstlisting}


\subsection{Remove}

If you didn't really want an environment named flowers, just remove it as follows:


\begin{lstlisting}[language=bash]
conda remove --name flowers --all
\end{lstlisting}

\subsection{Share}

You may want to share your environment with another person, for example, so they can re-create a test that you have done. To allow them to quickly reproduce your environment, with all of its packages and versions, you can give them a copy of your environment.yml file.

Export the environment file

To enable another person to create an exact copy of your environment, you will export the active environment file.

\begin{lstlisting}[language=bash]
conda env export > environment.yml
\end{lstlisting}

Use environment from file

Create a copy of another developer's environment from their environment.yml file:

\begin{lstlisting}[language=bash]
conda env create -f environment.yml
# remove environment
conda remove -n <your_environemnt> --all
\end{lstlisting}



\section{Module}


Create Public Module
conda, pypi, github

Step 0/4: Check your package name
Go to https://pypi.python.org/pypi/your_package_name to see your package name is valid

Step 1/4: Make your module 1
1.1 pip install cookiecutter

1.2 cookiecutter https://github.com/audreyr/cookiecutter-pypackage.git

1.3 Fill all necessary information

full_name [Audrey Roy Greenfeld]:
email [aroy@alum.mit.edu]:
github_username [audreyr]:
project_name [Python Boilerplate]:
project_slug []:
project_short_description:
release_date []:
pypi_username []:
year [2016]:
version [0.1.0]:
use_pypi_deployment_with_travis [y]:
It will create a directory

|- LICENSE
|- README.md
|- TODO.md
|- docs
|   |-- conf.py
|   |-- generated
|   |-- index.rst
|   |-- installation.rst
|   |-- modules.rst
|   |-- quickstart.rst
|   |-- sandman.rst
|- requirements.txt
|- your_package
|   |-- __init__.py
|   |-- your_package.py
|   |-- test
|       |-- models.py
|       |-- test_your_package.py
|- setup.py
Step 2/4: Git
Step 3/4: Pypi 3
1. Create your Pypi Account

2. Create a .pypirc configuration file in $HOME directory

[distutils]
index-servers =
  pypi

[pypi]
repository=https://pypi.python.org/pypi
username=your_username
password=your_password
3. Change your MANIFEST.in

recursive-include project_folder *
4. Upload your package to PyPI

python setup.py register -r pypi
python setup.py sdist upload -r pypi
Step 4/4: Conda 2
1. Install conda tools

conda install conda-build
conda install anaconda-client
2. Build a simple package with conda skeleton pypi

cd your_package_folder
mkdir conda
cd conda
conda skeleton pypi your_package
This creates a directory named your_package and three skeleton files in that directory

|- your_package
|   |-- bld.bat
|   |-- meta.yaml
|   |-- build.sh
3. Build your package

conda build your_package

# convert to all platform
conda convert -f --platform all
  C:\Anaconda\conda-bld\win-64\your_package-0.1.1-py27_0.tar.bz2
4. Upload packages to Anaconda

anaconda login
anaconda upload linux-32/your_package.tar.bz2
anaconda upload linux-64/your_package.tar.bz2
anaconda upload win-32/your_package.tar.bz2
anaconda upload win-64/your_package.tar.bz2
Create Private Module
Step 1: Make your module 1
1.1 pip install cookiecutter

1.2 cookiecutter https://github.com/audreyr/cookiecutter-pypackage.git

1.3 Fill all necessary information

full_name [Audrey Roy Greenfeld]:
email [aroy@alum.mit.edu]:
github_username [audreyr]:
project_name [Python Boilerplate]:
project_slug []:
project_short_description:
release_date []:
pypi_username []:
year [2016]:
version [0.1.0]:
use_pypi_deployment_with_travis [y]:
Step 2: Build your module
Change your MANIFEST.in

recursive-include project_folder *
Build your module with setup.py

cd your_project_folder

# build local
python setup.py build
> It will create a new folder in
> $PYTHON_HOME/Lib/sites-packages/your_project_name-0.1.0-py2.7.egg

# build distribution
python setup.py sdist
> It will create a zip file in $PROJECT_FOLDER/dist
Step 3: Usage your module
In the same machine

import your_project_name
In other machine

Python: Build & Install Local Package with Conda
Here is a step by step tutorial about building a local module package & install it from a custom channel 1

Step 1: Make a setup folder for your package with cookkiecutter
on terminal:


mkdir build
cd build
pip install cookiecutter
cookiecutter https://github.com/audreyr/cookiecutter-pypackage.git

Fill all necessary information

full_name [Audrey Roy Greenfeld]:
email [aroy@alum.mit.edu]:
github_username [audreyr]:
project_name [Python Boilerplate]:
project_slug []:
project_short_description:
release_date []:
pypi_username []:
year [2016]:
version [0.1.0]:
use_pypi_deployment_with_travis [y]:
It will create a directory

|- LICENSE
|- README.md
|- TODO.md
|- docs
|   |-- conf.py
|   |-- generated
|   |-- index.rst
|   |-- installation.rst
|   |-- modules.rst
|   |-- quickstart.rst
|   |-- sandman.rst
|- requirements.txt
|- your_package
|   |-- __init__.py
|   |-- your_package.py
|   |-- test
|       |-- models.py
|       |-- test_your_package.py
|- setup.py
Copy your real package into directory above & replace the package has been generated by cookkiecutter

Add this line to MANIFEST.in

recursive-include project_folder *
Step 2: Build conda package
mkdir conda
cd conda
mkdir channel
git clone https://github.com/hunguyen1702/condaBuildLocalTemplate.git
mv condaBuildLocalTemplate your_package_name #Which ones you have filled in `project_name` above
cd your_package_name
rm -rf .git README.md
Edit the file meta.yaml with the instruction inside it
cd ..
conda build your_package_name
Step 3: Create custom channel and install from local package
Create a channel directory

cd channel
Convert your_package you've built to all platform

conda convert --platform all ~/anaconda/conda-bld/linux-64/your_package_0.1.0-py27_0.tar.bz2
and this will create:

channel/
linux-64/
   package-1.0-0.tar.bz2
linux-32/
   package-1.0-0.tar.bz2
osx-64/
   package-1.0-0.tar.bz2
win-64/
   package-1.0-0.tar.bz2
win-32/
   package-1.0-0.tar.bz2
Register your package to your new channel

cd ..
conda index channel/linux-64 channel/osx-64 channel/win-64
Veriy your new channel

conda search -c file://path/to/channel/ --override-channels
If you see your_package's appearance, so it's worked

After that if you want to install that package from local, run this command:


conda install --use-local your_package

and when you want to create environment with local package from file, you just have export environment to .yml file and add this channels section before the dependencies section:


channels:
- file://path/to/your/channel/

\section{Production}

Production with docker
Base Image: magizbox/conda2.7/

Docker Folder

your_app/
├── app
│   ├── config
│   └── main.py
├── Dockerfile
└── run.sh
Dockerfile

FROM magizbox/conda2.7:4.0

ADD ./app /app
ADD ./run.sh /run.sh

RUN conda env create -f environment.yml
run.sh

source activate your_environment

cd /app

python main.py
Compose

 service:
  build: ./service-app
  command: 'bash run.sh'
Note: an other python conda with lower version (such as 3.5), will occur error when install requests package

\noindent \textbf{python 3.4 hay 3.5}

Có lẽ 3.5 là lựa chọn tốt hơn (phải có của tensorflow, pytorch, hỗ trợ mock)

### Quản lý môi trường phát triển với conda

Chạy lệnh `remove` để xóa một môi trường

\begin{lstlisting}[language=bash]
conda remove --name flowers --all
\end{lstlisting}

\section{Test với python}

\textbf{Sử dụng những loại test nào?}

Hiện tại mình đang viết unittest với default class của python là Unittest. Thực ra toàn sử dụng `assertEqual` là chính!

Ngoài ra mình cũng đang sử dụng tox để chạy test trên nhiều phiên bản python (python 2.7, 3.5). Điều hay của tox là mình có thể thiết kế toàn bộ cài đặt project và các dependencies package trong file `tox.ini`

\textbf{Chạy test trên nhiều phiên bản python với tox}

Pycharm hỗ trợ debug tox (quá tuyệt!), chỉ với thao tác đơn giản là nhấn chuột phải vào file tox.ini của project.

\section{Xây dựng docs với readthedocs và sphinx}

\noindent \textbf{20/12/2017}: Tự nhiên hôm nay tất cả các class có khai báo kế thừa ở project languageflow không thể index được. Vãi thật. Làm thằng đệ không biết đâu mà build model.

Thử build lại chục lần, thay đổi file conf.py và package\_reference.rst chán chê không được. Giả thiết đầu tiên là do hai nguyên nhân (1) docstring ghi sai, (2) nội dung trong package\_reference.rst bị sai. Sửa chán chê cũng vẫn thể, thử checkout các commit của git. Không hoạt động!

Mất khoảng vài tiếng mới để ý thằng readthedocs có phần log cho từng build một. Lần mò vào build gần nhất và build (mình nhớ là) thành công cách đây 2 ngày

\noindent Log build gần nhất

\begin{lstlisting}
Running Sphinx v1.6.5
making output directory...
loading translations [en]... done
loading intersphinx inventory from https://docs.python.org/objects.inv...
intersphinx inventory has moved: https://docs.python.org/objects.inv -> https://docs.python.org/2/objects.inv
loading intersphinx inventory from http://docs.scipy.org/doc/numpy/objects.inv...
intersphinx inventory has moved: http://docs.scipy.org/doc/numpy/objects.inv -> https://docs.scipy.org/doc/numpy/objects.inv
building [mo]: targets for 0 po files that are out of date
building [readthedocsdirhtml]: targets for 8 source files that are out of date
updating environment: 8 added, 0 changed, 0 removed
reading sources... [ 12%] authors
reading sources... [ 25%] contributing
reading sources... [ 37%] history
reading sources... [ 50%] index
reading sources... [ 62%] installation
reading sources... [ 75%] package_reference
reading sources... [ 87%] readme
reading sources... [100%] usage

looking for now-outdated files... none found
pickling environment... done
checking consistency... done
preparing documents... done
writing output... [ 12%] authors
writing output... [ 25%] contributing
writing output... [ 37%] history
writing output... [ 50%] index
writing output... [ 62%] installation
writing output... [ 75%] package_reference
writing output... [ 87%] readme
writing output... [100%] usage
\end{lstlisting}

Log build hồi trước

\begin{lstlisting}[language=bash]
Running Sphinx v1.5.6
making output directory...
loading translations [en]... done
loading intersphinx inventory from https://docs.python.org/objects.inv...
intersphinx inventory has moved: https://docs.python.org/objects.inv -> https://docs.python.org/2/objects.inv
loading intersphinx inventory from http://docs.scipy.org/doc/numpy/objects.inv...
intersphinx inventory has moved: http://docs.scipy.org/doc/numpy/objects.inv -> https://docs.scipy.org/doc/numpy/objects.inv
building [mo]: targets for 0 po files that are out of date
building [readthedocs]: targets for 8 source files that are out of date
updating environment: 8 added, 0 changed, 0 removed
reading sources... [ 12%] authors
reading sources... [ 25%] contributing
reading sources... [ 37%] history
reading sources... [ 50%] index
reading sources... [ 62%] installation
reading sources... [ 75%] package_reference
reading sources... [ 87%] readme
reading sources... [100%] usage

/home/docs/checkouts/readthedocs.org/user_builds/languageflow/checkouts/develop/languageflow/transformer/count.py:docstring of languageflow.transformer.count.CountVectorizer:106: WARNING: Definition list ends without a blank line; unexpected unindent.
/home/docs/checkouts/readthedocs.org/user_builds/languageflow/checkouts/develop/languageflow/transformer/tfidf.py:docstring of languageflow.transformer.tfidf.TfidfVectorizer:113: WARNING: Definition list ends without a blank line; unexpected unindent.
../README.rst:7: WARNING: nonlocal image URI found: https://img.shields.io/badge/latest-1.1.6-brightgreen.svg
looking for now-outdated files... none found
pickling environment... done
checking consistency... done
preparing documents... done
writing output... [ 12%] authors
writing output... [ 25%] contributing
writing output... [ 37%] history
writing output... [ 50%] index
writing output... [ 62%] installation
writing output... [ 75%] package_reference
writing output... [ 87%] readme
writing output... [100%] usage
\end{lstlisting}

Đập vào mắt là sự khác biệt giữa documentation type

Lỗi

\begin{lstlisting}[language=bash]
building [readthedocsdirhtml]: targets for 8 source files that are out of date
\end{lstlisting}

Chạy

\begin{lstlisting}[language=bash]
building [readthedocs]: targets for 8 source files that are out of date
\end{lstlisting}

Hí ha hí hửng. Chắc trong cơn bất loạn sửa lại settings đây mà. Sửa lại nó trong phần Settings (Admin &gt; Settings &gt; Documentation type)

![](https://magizbox.files.wordpress.com/2017/10/screenshot-from-2017-12-20-09-54-23.png)

Khi chạy nó đã cho ra log đúng

\begin{lstlisting}[language=bash]
building [readthedocsdirhtml]: targets for 8 source files that are out of date
\end{lstlisting}

Nhưng vẫn lỗi. Vãi!!! Sau khoảng 20 phút tiếp tục bấn loạn, chửi bới readthedocs các kiểu. Thì để ý dòng này

Lỗi

\begin{lstlisting}[language=bash]
Running Sphinx v1.6.5
\end{lstlisting}


Chạy

\begin{lstlisting}[language=bash]
Running Sphinx v1.5.6
\end{lstlisting}

Ngay dòng đầu tiên mà không để ý, ngu thật. Aha, Hóa ra là thằng readthedocs nó tự động update phiên bản sphinx lên 1.6.5. Mình là mình chúa ghét thay đổi phiên bản (code đã mệt rồi, lại còn phải tương thích với nhiều phiên bản nữa thì ăn c** à). Đầu tiên search với Pycharm thấy dòng này trong `conf.py`

\begin{lstlisting}[language=bash]
# If your documentation needs a minimal Sphinx version, state it here.
# needs_sphinx = '1.0'
\end{lstlisting}

Đổi thành

\begin{lstlisting}[language=bash]
# If your documentation needs a minimal Sphinx version, state it here.
needs_sphinx = '1.5.6'
\end{lstlisting}

Vẫn vậy (holy sh*t). Thử sâu một tẹo (thực sự là rất nhiều tẹo). Thấy cái này trong trang Settings

![](https://magizbox.files.wordpress.com/2017/10/screenshot-from-2017-12-20-10-01-39.png)

Ờ há. Thằng đần này cho phép trỏ đường dẫn tới một file trong project để cấu hình dependency. Haha.
Tạo thêm một file `requirements` trong thư mục `docs` với nội dung

\begin{lstlisting}
sphinx==1.5.6
\end{lstlisting}


Sau đó cấu hình nó trên giao diện web của readthedocs

![](https://magizbox.files.wordpress.com/2017/10/screenshot-from-2017-12-20-10-04-49.png)

Build thử. Build thử thôi. Cảm giác đúng lắm rồi đấy. Và... nó chạy. Ahihi

![](https://magizbox.files.wordpress.com/2017/10/screenshot-from-2017-12-20-10-06-32.png)

\textbf{Kinh nghiệm}

* Khi không biết làm gì, hãy làm 3 việc. Đọc LOG. Phân tích LOG. Và cố gắng để LOG thay đổi theo ý mình.

PS: Trong quá trình này, cũng không thèm build thằng PDF với Epub nữa. Tiết kiệm được bao nhiêu thời gian.
